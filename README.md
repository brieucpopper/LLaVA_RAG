This repo is a proof of concept on how to do simple RAG for a multimodal setting (using LLaVA).

Inspired by the deeplearning.ai MOOC https://learn.deeplearning.ai/login?callbackUrl=https%3A%2F%2Flearn.deeplearning.ai%2Fcourses%2Fmultimodal-rag-chat-with-videos

the script proof_of_concept_RAG.py illustrates the whole process for only 4 images



You can download the flickr8k data easily by runnign the dl_images.py script

You can use the environment.yml conda env to run the scripts, you will need a GPU that fits the models in memory though